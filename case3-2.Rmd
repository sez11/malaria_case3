---
title: "case3-2"
author: "Sarah Zimmermann, Wuming Zhang, Adam Wood"
date: "November 9, 2017"
output: pdf_document
---

#Data
```{r, echo=FALSE, results="hide", message=FALSE, warning=FALSE}
library(ggplot2)
library(devtools)
library(mice)
library(lattice)
library(MASS)
gambia= read.csv("gambiaMissing.csv") 
```

#Multiple Imputation/Chained Regression
```{r, echo=FALSE, results="hide", message=FALSE, warning=FALSE}
gambia$BEDNET = as.factor(gambia$BEDNET)
tempData <- mice(gambia, m=5,maxit=50,meth='logreg', seed=500)
summary(tempData)
completedData <- complete(tempData,1)
#this function returns the imputed data set, with the second parameter in the function determining which data set you are returning(the 1st of the 5 imputed data sets in this case)
```
The multiple imputation method using chained regression was utilized to impute missing data for the bednet variable in the *gambia* data set. The $mice$ package provides several functions for easy implementation of multiple imputation. Functions **mice()**, **complete()**, and **with()** allow us to apply multiple imputation for missing data, replace missing data with imputed data, and use the imputed data set to create a model, respectively. 

##Inspection of Missing Data
```{r, echo=FALSE, results="hide", message=FALSE, warning=FALSE}
xyplot(tempData,Y ~ BEDNET + AGE+ PHC+ GREEN,pch=18,cex=1)
#unfortunately provides little information when comparing imputed to observed

stripplot(tempData, pch=20, cex=1.2)
#would be a useful plot for largely continuous data without so many binary or ordinal variables (both Y, PHC and Bednet are binary, and Age and Green only have 4 unique values each)

densityplot(tempData, ~BEDNET)
#the densities for each imputed data set follow a similar shape to the observed density curve
```

In order to ensure the multiple imputation process functioned as expected, we analyze the distributions of the imputed data sets versus the originally observed data. The scatterplot of malaria presence vs. each of the predictor variables fails to provide any insight, and in cases where fewer variables are binary or few in unique value, it might be more useful. The strip plot also yields very little with respect to the relationship between imputed and observed data, but does illustrate that the *bednet* variable is the only variable with missing data (previously known). The density plot provides us with the most meaningful information regarding the imputed data sets and the observed data.

In our density plot, the 5 magenta density curves represent the 5 imputed data sets, while the blue density curve represents the density of observed data. In determining whether the imputed data for missing values in the bednet variable are plausible, we want to determine if the imputed data density curves follow a similar curvature to the observed data density curve. As illustrated, the 5 magenta curves follow a similar shape to the observed data curve. It is of note to mention that all 5 imputed data sets densities fall below the density of the observed data for the number of individuals without a bednet. 2 imputed data sets fall below the observed density for individuals with a bednet, 2 above the observed density, and 1 with a density of individuals with a bednet very close to the observed. It appears that each of the 5 imputed data sets seems plausible and have similar shape to the blue observed curve. 


#Model
```{r, echo=FALSE, results="hide", message=FALSE, warning=FALSE}
modelFit1 <- with(tempData,glm(Y~ BEDNET+AGE+PHC+GREEN))
summary(pool(modelFit1))
#takes the imputed data sets, fits a model to each data set, and pools together results

tempData2 <- mice(gambia,m=50,seed=245435)

densityplot(tempData2, ~BEDNET)

modelFit2 <- with(tempData2,glm(Y~BEDNET+AGE+PHC+GREEN))
summary(pool(modelFit2))
#50 imputed data sets instead of 5 to pool together and fit a model
```
To alleviate dependance created by our choice in the **mice()** function seed selection, we use the multiple imputation method to create 50 imputed data sets. The density plot for these 50 data sets follow very similar shape to the observed density curve, and so we proceed with model fitting. 

The summary of our model fit with 50 imputed data sets indicates that the variables *age* and *PHC* (presence of a health clinic in the village) are statistically significant with p-values under 0.01. Bednet use was not statistically significant, with a p-value over 0.1. This provides insight into the effects of bednet use on malaria presence in the individual, and indicates that bednet use is not as impactful on predicting cases of malaria as previously thought. Under the current model, age and presence of a health clinic in the area are the strongest variables in predicting malaria cases. 


#Model Diagnostics and Selection

## Interaction Analysis

Since Malaria is a mosquito-borne disease, we suspect that the presence of bed net would be an influential factor. Some other factor, such as the presence of a public clinic, could potentially have some interaction with the bed net variable. In other words, the effect of having a public clinic to malaria appearance could possibly vary with whether a bed net is used. We picked one of the imputed datasets and fit a logistic regression model with an interaction term between the bed net and public clinic. The resulting plots below show that the slopes of $Y~PHC$ are quite different for different $BEDNET$ variable values.

```{r, echo=FALSE, results="hide", message=FALSE, warning=FALSE}
library(effects)
model = glm(Y~BEDNET+AGE+PHC+GREEN+BEDNET:PHC, data = completedData)
#this is our most current and up to date model
plot(allEffects(model))
```

## Model Selection
```{r, echo=FALSE, results="hide", message=FALSE, warning=FALSE}
modelBase <- with(tempData2,glm(Y~1))

modelFit3 <- with(tempData2,glm(Y~BEDNET+AGE+PHC+GREEN+BEDNET:PHC))
summary(pool(modelFit3))

pool.compare(modelFit2, modelBase, data = tempData2, method = "likelihood")$pvalue
# weird that the fitted model is not significant compared to a model with only intercept....
pool.compare(modelFit3, modelFit2, data = tempData2, method = "likelihood")$pvalue
```

We then start off the model selection process by first constructing a naive model with intercept only. We then compare our full model, $Y=\alpha_1BEDNET+\alpha_2AGE+\alpha_3PHC+\alpha_4GREEN+\alpha_5$ with this naive model using a likelihood ratio test. From the p-value above, we can observe that the full model is not significant compared to the naive model. We also use a similar technique to compare a model with an extra interaction variable but we found that it is not statistically significant as well. This appears to be different from what we expected, and we are planning to use cross-validation to further verify this finding. For now, we choose to use the model with all variables and an additional interaction term as our most current model, that is, $Y=\alpha_1BEDNET+\alpha_2AGE+\alpha_3PHC+\alpha_4GREEN+\alpha_5BEDNET*PHC+\alpha_6$. 


#Model Residuals and AIC
```{r}
plot(model)

#stepAIC starting with the intercept only model
stepAIC(glm(Y~1, data = completedData), scope = ~ BEDNET + AGE + PHC + GREEN + BEDNET:PHC)
```
The residuals vs. fitted plot illustrates a dichotomous trend amongst residuals, with two separate, decreasing lines of residuals on both sides of the horizontal zero line. In evaluating the residuals for a logistic regression model, this is not surprising. If the observed value is 0, we will have negative residuals because we will predict higher than 0, and vice versa for observed values at 1. 

The **stepAIC()** function allows us to evaluate our model using stepwise variable selection, with AIC as our criterion. The function's output, run over our current model, determined that the model with the lowest AIC is: $Y=\alpha_1AGE+\alpha_2PHC$. In future revisions, we will evaluate the consequences of using AIC as the primary variable selection criterion, as well as the consequences of variable selection processes in the context of this study. 

# Model Interpretation

#Future Revisions

In future revisions of this analysis, we look to examine the effects of choosing AIC as the primary variable selection criterion, as well as the effect of using a stepwise variable selection technique has on our analysis in this setting. We aim to utilize other techniques for model validation, i.e. cross validation, to further solidify our model selection. Other interaction terms will be considered and tested to determine their contributions or lack thereof to our current model. 

#Credits 

This was a team effort. Adam contributed most heavily to the write up, model diagnostics (residuals and AIC), and evaluation of our model with imputed data using plots. 

#References 

https://www.r-bloggers.com/imputing-missing-data-with-r-mice-package/

http://freakonometrics.hypotheses.org/8210